# Gamal Du Dabashti: A hebrew finetuned instruction LLaMA

**Work in progress**

This is an instruction finetuned version of LLaMA using a translated instruction dataset to the Hebrew language. The finetune is performed using the LoRA method. 

## Acknowledgments
[Cabrita](https://github.com/22-hours/cabrita)

[LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)

[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)

[Alpaca Lora](https://github.com/tloen/alpaca-lora)

[Cleaned Alpaca Dataset](https://github.com/gururise/AlpacaDataCleaned)

[Hugging Face](https://huggingface.co/)